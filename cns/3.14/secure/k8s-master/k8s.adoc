== Kubernetes API servers

//'''
//
//title: Kubernetes API servers
//type: single
//url: "/3.14/secure/k8s-master/k8s/"
//weight: 10
//menu:
//  3.14:
//    parent: "k8s-master"
//    identifier: "k8s-api"
//canonical: https://docs.aporeto.com/saas/secure/k8s-master/k8s/
//aliases: [
//  "../setup/k8s-master/k8s/"
//]
//
//'''

=== Requirements

You need to have the following setup prepared and running before continuing with this guide:

* Installed and configured xref:../../start/apoctl/apoctl.adoc[apoctl]
* A running Kubernetes cluster - in this guide, it is assumed it has been installed using `kubeadm`
* Full access to the Kubernetes master hosts
* Installed and confirmed Aporeto Kubernetes setup as described xref:../../start/enforcer/k8s.adoc[here].

[NOTE]
====
For maximum security we recommend installing the enforcers in your Kubernetes cluster as an RPM and run `enforcerd` as a system service. This segregates the component enforcing security from your cluster and it avoids for it to become an attack vector from inside the cluster. You can find the instructions for how to run the enforcer on a Kubernetes node/master as a Linux service xref:../../start/enforcer/linux.adoc[here]
====

=== Prepare apoctl

Make sure that for all the following commands in this guide, you point `apoctl` to the right Aporeto namespace.
Export the following variable to do so:

[,console]
----
# Replace /path/to/kubernetes/cluster with the namespace where your Kubernetes cluster resides in Aporeto
export APOCTL_NAMESPACE=/path/to/kubernetes/cluster
----

Confirm that `apoctl` is now pointing to the right namespace as well as platform by running:

[,console]
----
apoctl api info
----

In the output the namespace should match the namespace that you set in the instructions above.

=== Create Aporeto resources

Before we can activate and create the Aporeto service, we have to create a Kubernetes API definition, as well as a host service and mapping.

Begin by creating the HTTP Resource Spec definition for the Kubernetes API:

[,console]
----
cat <<EOF | apoctl api create httpresourcespec -f -
name: kubernetes-api
description: "The Kubernetes API spec"
associatedTags:
- api=kubernetes
endpoints:
- URI: /*
  allowedScopes: []
  methods:
  - GET
  - POST
  - PUT
  - DELETE
  - PATCH
  - HEAD
  public: true
  scopes: []
EOF
----

[TIP]
====
This is the area where you can later further secure specific access to the Kubernetes API. By default and for a first installation, leave everything open and public. You can then afterwards look at which users/services access the API, and if you want to further lock them down.
====

Next, create a host service which essentially identifies the Kubernetes API server on master nodes.

[,console]
----
cat <<EOF | apoctl api create hostservice -f -
name: okd_api
description: "The Kubernetes API service"
associatedTags:
- hostservice=kubernetes-api
services:
- tcp/8443
EOF
----

Afterwards, we need to map this host service to the enforcers which are running it. Use the following command for that:

[,console]
----
cat <<EOF | apoctl api create hostservicemappingpolicy -f -
name: okd_api
description: "The Kubernetes API service"
object:
- - hostservice=kubernetes-api
subject:
- - $name=enforcer-name-1
- - $name=enforcer-name-2
EOF
----

[WARNING]
====
You need to replace `$name=enforcer-name-1` and `$name=enforcer-name-2` with the name of the enforcers that are running the Kubernetes API server in your Kubernetes cluster. Any other selector that matches all master nodes can be used as well, of course.
====

=== Prepare the master nodes

Create a file with the Aporeto platform CA so that it can  be used in the request header configuration on all the master nodes:

[,console,subs="+attributes"]
----
curl -o - https://{ctrl-plane-api-url}/_meta/ca > /etc/kubernetes/pki/aporeto-ca.crt
----

Now you need to edit the `/etc/kubernetes/manifests/kube-apiserver.yaml` file to adjust the configuration for the request header configuration. Open the file in an editor and adjust/add the following kube-apiserver command section of the container configuration:

[,yaml]
----
    - --requestheader-client-ca-file=/etc/kubernetes/pki/aporeto-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
----

[WARNING]
====
Some of these values might already exist. Ensure to replace them with the exact content from above.
====

Restart the Kubernetes API server by deleting the static pod that is running on the master server:

[,console]
----
kubectl delete pod -l component=kube-apiserver -n kube-system
----

Ensure the API server pod really restarts and comes back up without any problems.

Your Kubernetes cluster is now prepared to be protected with Aporeto. The final step is now in the next section to create the Aporeto service and activate the protection.

=== Create the Aporeto service

Before you create the service, create a file in which you can more easily manage the configuration of the service.

Create a file _kubernetes-api-example.yaml_ with the following contents:

[,yaml]
----
name: "kubernetes-api"
description: "The Kubernetes API server"

type: HTTP

# This has to be set to JWT.
# It means that MTLS is tried regardless, but JWT will also be verified if present, and enforced if no MTLS has been done.
authorizationType: JWT

# put down all IPs under which the Kubernetes API server is accessed by which by default is:
# - the master server's IP address (external and internal as needed)
# - the default/kubernetes service IP (for in-cluster access)
IPs:
  # internal master node IP, replace with the correct one
  - 192.0.2.1
  # external master node IP, replace with the correct one, or remove completely if public access is not desired
  - 203.0.113.1
  # the kubernetes service cluster IP in the default namespace, replace with the correct one
  - 10.96.0.1

# put all the hosts here that the Kubernetes API is accessed by
# especially in-cluster, it is access through its DNS names
hosts:
  # the hostname as well as fqdn of the host, adjust as necessary
  - kubeapiplane-1
  - kubeapiplane-1.c.example.internal
  # all internal entries to reach the kubernetes service
  # you most likely want to keep these
  - kubernetes
  - kubernetes.default
  - kubernetes.default.svc
  - kubernetes.default.svc.cluster.local

# the Kubernetes API port where it listens
# kubeadm: 6443
# OpenShift: 8443
port: 6443
exposedPort: 6443

# random port on where you'll have to access the Kubernetes API from now on
# NOTE: this requires reconfiguration of your ~/.kube/config files
# NOTE: this requires reconfiguration of the default/kubernetes Service and Endpoint
#       replace the target port from its original 6443/8443 to this port here
publicApplicationPort: 443

# must be set to true: the Kubernetes API server always runs TLS
exposedServiceIsTLS: true

# because we need to run the same cert and keys as the Kubernetes API server
TLSType: External

# must be copied from the Kubernetes API server cert from:
# kubeadm: /etc/kubernetes/pki/apiserver.crt
# OpenShift: /etc/origin/master/master.server.crt
TLSCertificate: |
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----

# must be copied from the Kubernetes API server key from:
# kubeadm: /etc/kubernetes/pki/apiserver.key
# OpenShift: /etc/origin/master/master.server.key
TLSCertificateKey: |
  -----BEGIN RSA PRIVATE KEY-----
  ...
  -----END RSA PRIVATE KEY-----

# put the public keys / certs here that are used for signing JWTs
# for Service Accounts
# kubeadm: /etc/kubernetes/pki/sa.key
# OpenShift: /etc/origin/master/serviceaccounts.public.key
#
# NOTE: Furthermore, also put all other public JWT signing keys here
# that are used to authenticate against Kubernetes. For example, if you
# are using Keycloak as an Identity Provider and you integrate it
# in Kubernetes through OIDC, then you want to export the public
# signing keys and put them here as well
JWTSigningCertificate: |
  -----BEGIN PUBLIC KEY-----
  ...
  -----END PUBLIC KEY-----
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----

# put the Kubernetes CA cert here
# kubeadm: /etc/kubernetes/pki/ca.crt
# OpenShift: /etc/origin/master/ca.crt
MTLSCertificateAuthority: |
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----

# put the Kubernetes CA cert here as well from
# kubeadm: /etc/kubernetes/pki/ca.crt
# OpenShift: /etc/origin/master/ca-bundle.crt
# This is needed because the enforcer establishes outgoing
# connections to the Kubernetes API server that need to be validated.
trustedCertificateAuthorities: |
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----

# This is **vital** for the MTLS authentication to work
# NOTE: the targetHTTPHeader names must match the Kubernetes API server flags:
#       --requestheader-username-headers=X-Remote-User
#       --requestheader-group-headers=X-Remote-Group
claimsToHTTPHeaderMappings:
  - claimName: CN
    targetHTTPHeader: X-Remote-User
  - claimName: O
    targetHTTPHeader: X-Remote-Group

# match this to your HTTPResourceSpec definition of the Kubernetes API
exposedAPIs:
  - - api=kubernetes

# needs to select the Kubernetes API host service
selectors:
  - - hostservice=kubernetes-api
----

Now make a copy of this file:

[,console]
----
cp kubernetes-api-example.yaml kubernetes-api.yaml
----

And now edit the freshly copied _kubernetes-api.yaml_ and adjust and replace all values in there as required.
It can take quite some time to get all values together.
However, it is crucial that all values are correct before proceeding.

Once you are sure that you have adjusted all values correctly in the _kubernetes-api.yaml_ file, create the Aporeto service.

[,console]
----
apoctl api create service -f kubernetes-api.yaml
----

The Kubernetes API is now protected with Aporeto and reachable at the _publicApplicationPort_.
Note that applications will still be able to reach the API on the original port without Aporeto protection.
If you want to force also all pod traffic to use the Aporeto protected port, you will have to adjust the Kubernetes service and endpoint objects.
Refer to the <<_advanced,next section>> to learn more about this.

=== Update kubeconfig

To start using the protected Kubernetes API endpoint, you are going to have to update the kubeconfig - the Kubernetes client configuration.
You can either do so by editing the file directly (e.g. at `~/.kube/config`), or you can do it with the following commands.

List the current available contexts in the configuration:

[,console]
----
kubectl config get-contexts
----

Identify the _cluster_ entry name of the configuration from the list above and retrieve the currently configured server URL:

[,console]
----
kubectl config view -o \
jsonpath='{.clusters[?(@.name == "cluster-name")].cluster.server}{"\n"}'
----

[WARNING]
====
Make sure to replace _cluster-name_ in the above command with the cluster name from the list of the output from all available contexts.
====

Now update the server URL by replacing the port in the URL with the newly configured `publicApplicationPort` of the Aporeto service.

[,console]
----
kubectl config set-clusters cluster-name \
--server=https://kubeapiplane-1.c.example.internal:8443
----

[WARNING]
====
Make sure to replace `+https://kubeapiplane-1.c.example.internal:8443+` with the correct URL and `publicApplicationPort` of the Aporeto service.
====

Your kubeconfig is now set up to use the protected Kubernetes API endpoint.

[#_advanced]
=== Advanced

All topics in the advanced section of this guide are optional. However, they can add more visibility and security to your cluster.

==== Enable Kubernetes API protection for all pods

If you want to fully protect access to the Kubernetes API server with Aporeto, you can additionally configure the cluster internal service and endpoint to point to the Aporeto protected Kubernetes API service.

Get the Kubernetes service object:

[,console]
----
kubectl get service kubernetes -n default -o yaml
----

This should provide you with output similar to the following:

[,yaml]
----
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2018-12-21T16:32:51Z"
  labels:
    component: apiserver
    provider: kubernetes
  name: kubernetes
  namespace: default
  resourceVersion: "24"
  selfLink: /api/v1/namespaces/default/services/kubernetes
  uid: 0f93fec6-053e-11e9-aa9f-42010a8a0018
spec:
  clusterIP: 10.96.0.1
  ports:
  - name: https
    port: 443
    protocol: TCP
    targetPort: 6443
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
----

You need to update the `targetPort` of the `https` port in the definition above to match the `publicApplicationPort` of the Aporeto service. You can do this by running the following patch command:

[,console]
----
kubectl patch service kubernetes -p \
'{"spec":{"ports":[{"port":443,"targetPort":443}]}}' -n default
----

[WARNING]
====
Ensure that the `targetPort` really matches the `publicApplicationPort` of the Aporeto service.
====

Get the Kubernetes endpoints objects:

[,console]
----
kubectl get endpoints kubernetes -n default -o yaml
----

This should provide you with output similar to the following:

[,yaml]
----
apiVersion: v1
kind: Endpoints
metadata:
  creationTimestamp: "2018-12-21T16:32:51Z"
  name: kubernetes
  namespace: default
  resourceVersion: "42"
  selfLink: /api/v1/namespaces/default/endpoints/kubernetes
  uid: 0f9cf317-053e-11e9-aa9f-42010a8a0018
subsets:
- addresses:
  - ip: 192.0.2.1
  ports:
  - name: https
    port: 6443
    protocol: TCP
----

You need to update the `port` of the `https` port in the definition above for all addresses to match the `publicApplicationPort` of the Aporeto service. You can do this by carefully running the following patch command:

[,console]
----
kubectl patch endpoints kubernetes --type json -p \
'[{"op": "replace", "path": "/subsets/0/ports/0/port", "value":443}]' -n default
----

[WARNING]
====
Ensure that the `path` of the JSON patch is correct. In this case it patches the first element of the subsets and the first element of the ports which point to the `https` port in this example. Also ensure that the `value` will become the same value of the `publicApplicationPort` of the Aporeto service.
====

Good job!
Now all pod network communications with the Kubernetes API go through the protected Aporeto service.
