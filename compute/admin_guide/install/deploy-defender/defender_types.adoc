== Defender Types

Defenders enforce the policies you set in Console.
They come in a number of different flavors.
Each flavor is designed for protecting specific types of cloud-native resources and for optimal deployment into the environment, with full support for automated workflows.
Use the following flow chart to choose the best Defender for the job.

In general, deploy Container Defender whenever you can.
It offers the most features, it can simultaneously protect both containers and host, and nothing needs to be embedded inside your containers for Defender to be able to protect them.

image::defender_types_decision_tree.png[width=800]


[#container-defender]
=== Container Defender (Linux and Windows)

Install Container Defender on any host that runs a container workload.
Container Defender protects both your containers and the underlying host.
Docker must be installed on the host because this Defender type runs as a container.

Container Defender offers the richest set of capabilities.
The deployment is also the simplest.
After deploying Container Defender to a host, it can immediately protect and monitor your containers and host.
No additional steps are required to rebuild your containers with an agent inside.
Container Defender should always be your first choice whenever possible.

There are some minimum requirements to run Container Defender.
You should have full control over the host where Container Defender runs.
It must be able to run alongside the other containers on the host with xref:../system_requirements.adoc#kernel[select kernel capabilities].
And it must be able to run in the host's network and process namespace.

Deploy one Container Defender per host.
Container Defender can be deployed in several ways:

* With cluster constructs.
Container orchestrators often provide native capabilities for deploying agents, such as Defender, to every node in the cluster.
Prisma Cloud leverages these capabilities to install Defender.
Kubernetes and OpenShift, for example, offer DaemonSets
As such, Container Defender is deployed as a DaemonSet on Kubernetes
* As a stand-alone entity.
Stand-alone Container Defenders are installed on hosts that are not part of a cluster.


[#host-defender]
=== Host Defender (Linux and Windows)

Host Defender utilizes Prisma Cloud's model-based approach for protecting hosts that do not run containers.
This Defender type lets you extend Prisma Cloud to protect all the hosts in your environment, regardless of their purpose.
Defender runs as a systemd service on Linux and a Windows service on Windows.
If Docker is deployed on your host, deploy a container Defender to protect the containers and the underlying host.

Deploy one Host Defender per host.
Do not deploy Host Defender if you've already deployed Container Defender to a host.
Container Defender offers the same host protection capabilities as Host Defender.


=== Serverless Defender

Serverless Defenders offer runtime protection for https://docs.aws.amazon.com/lambda/latest/dg/welcome.html[AWS Lambda functions] and https://azure.microsoft.com/en-us/services/functions/[Azure Functions].
Serverless Defender must be xref:./serverless/serverless.adoc[embedded inside your functions].
Deploy one Serverless Defender per function.


=== App-Embedded Defender

If you use services providing containers on demand, you can run containers, but the service abstracts away the underlying cluster, host, operating system, and software modules.
Without access to those hooks, container Defenders can't monitor and protect resources in those environments.
Instead, embed an app-embedded Defender directly inside your workload running in the container to establish a point of control.
You can manually embed the Defenders or use automated workflows to embed Defenders using Fargate or Dockerfile.

Using Dockerfile, you deploy one app-embedded Defender per container.
Using Fargate, you deploy one app-embedded Defender per task.

==== Fargate

If you have an AWS Fargate task, deploy App-Embedded Fargate Defender.

A key attribute of the App-Embedded Fargate Defender is that you don't need to change how the container images in the task are built.
The process of embedding the App-Embedded Defender simply manipulates the task definition to inject a Prisma Cloud sidecar container, and start existing task containers with a new entry point, where the entry point binary is hosted by the Prisma Cloud sidecar container.
The transformation of an unprotected task to a protected task takes place at the task definition level only.
The container images in the task don't need to be manually modified.
This streamlined approach means that you don't need to maintain two versions of an image (protected and unprotected).
You simply maintain the unprotected version, and when you protect a task, Prisma Cloud dynamically injects App-Embedded Defender into it.

The Prisma Cloud sidecar container has a couple of jobs:

* Hosts the Defender binary that gets injected into containers in the task.

* Proxies all communication to Console.
Even if you have multiple containers in a task, it appears as a single entity in Console's dashboard.

* Synchronizes policy with Console and sends alerts to Console.


==== Dockerfile

The Docker image format, separate from the runtime, is becoming a universal runnable artifact.
If you're not using Fargate, but something else that runs a Docker image, such as Azure Container Instances, use the App-Embedded Defender with the Dockerfile method.

Provide a Dockerfile, and Prisma Cloud returns a new version of the Dockerfile in a bundle.
Rebuild the new Dockerfile to embed Prisma Cloud into the container image.
When the container starts, Prisma Cloud App-Embedded Defender starts as the parent process in the container, and it immediately invokes your program as its child.

There are two big differences between this approach and the Fargate approach:

* With the Fargate approach, you don't change the actual image.
With the Dockerfile approach, you have the original image and a new protected image.
You must modify the way your containers are built to embed App-Embedded Defender into them.
You need to make sure you tag and deploy the right image.

* Each Defender binary makes it's own connection to Console.
In the Console dashboard, they are each counted as unique applications.

Nothing prevents you from protecting a Fargate task using the Dockerfile approach, but it's inefficient.


==== Manual

Use the manual approach to protect almost any type of runtime.
If you're not running a Docker image, but you still want Prisma Cloud to protect it, deploy App-Embedded Defender with the manual method.
Download the App-Embedded Defender, set up the required environment variables, then start your program as an argument to the App-Embedded Defender.

If you choose the manual approach, you have to figure out how deploy, maintain, and upgrade your app on your own.
While the configuration is more complicated, it's also the most universal option because you can protect almost any executable.


=== Tanzu Application Service Defender

xref:../../vulnerability_management/vmware_tanzu_blobstore.adoc[Tanzu Application Service (TAS) Defenders] run on your TAS infrastructure.
TAS Defenders provide nearly all the same capabilities as Container Defenders, as well as the ability to scan droplets in your blobstores for vulnerabilities.
For specific differences between TAS Defenders and Container Defenders, see the xref:./orchestrator/install_tas_defender.adoc[TAS Defender install article].

The TAS Defender is delivered as a tile that can be installed from your TAS Ops Manager Installation Dashboard.


=== Defender capabilities

The following table summarizes the key functional differences between Defender types.

[cols="3,2,1,1,1,1", frame="topbot"]
|====
2+^|Capabilities 4+^|Defender type

2+|
|Container^1^
|Host
|Serverless
|App-Embedded

.3+|*Deployment methods*
|*Console UI*
|Y
|Y
|Y
|Y

|*API*
|Y
|Y
|Y
|Y

|*twistcli*
|Y
|
|
|Y

|*Vulnerability management*
|
|Y
|Y
|Y^2^
|Y^3^

|*Compliance*
|
|Y
|Y
|Y^2^
|Y^4^

.5+|*Runtime defense*
|*Behavioral modeling*
|Y
|
|
|

|*Process*
|Y
|Y
|Y
|Y

|*Networking*
|Y
|Y
|Y
|Y

|*File system*
|Y
|Y
|Y
|Y

|*Forensics*
|Y
|Y
|
|Y

.2+|*Access control*
|*Kubernetes auditing*
|Y^5^
|
|
|Y^5^

|*Admission control*
|Y
|
|
|

.2+|*Firewalls*
|*WAAS*
|Y
|Y
|Y
|Y

|*CNNS*
|Y
|Y
|
|

.1+|*Radar (visualization)*
|*Radar*
|Y
|Y
|Y
|

|====

^1^
Container Defender supports all Host Defender capabilities.

^2^
Normally Defender scans workloads for vulnerabilities and compliance issues.
For serverless functions, Console does the scanning.
In the Console, create a configuration that points to your repository of functions in your cloud provider.

^3^
Vulnerability management for deployed images only. 
Registry scanning by app-embedded Defenders is not supported.

^4^
Image compliance and custom compliance checks only.
The trusted images feature isn't supported.

^5^
Kuberentes auditing is done by the Console, and not by the Defenders. 
In the Console, enable Kubernetes auditing and create a configuration that points to your cluster.

=== Connectivity

Defender must be able to communicate with Console over the network because it pulls policies down and sends data (alerts, events, etc) back to Console.

ifdef::compute_edition[]
In simple environments, where your hosts run on the same subnet, you can connect to Console using the host’s IP address or hostname.
In more complex environments, where your setup runs in the cloud, it can be more difficult to determine how Defender connects to Console.
When setting up Defender, use whichever address routes over your configuration and lets Defender connect to Console.

For example, Console might run in one Virtual Private Cloud (VPC) in AWS, and your containers might run in another VPC.
Each VPC might have a different RFC1918 address space, and communication between VPCs might be limited to specific ports in a security group.
Use whichever address lets Defender connect to Console.
It might be a publicly exposed IP address, a hostname registered with a DNS, or a private address NAT’ed to the actual IP address assigned to Console.
For more information about setting up name resolution in complex networks, see
xref:../../deployment_patterns/best_practices_dns_cert_mgmt.adoc#[Best practices for for DNS and certificate management].
endif::compute_edition[]


