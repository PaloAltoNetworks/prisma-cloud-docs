[#ide22ea409-a7e8-48a2-914b-17e56f7915ed]
== Remediate Alerts for IAM Security

// Manually remediate your IAM security misconfigurations by running CLI commands or automatically remediate overly permissive users with a custom python script.

The IAM security module provides two options for remediating alerts so that you can enforce the principle of least privilege across your AWS, Azure, and GCP environments. You can manually remediate the alerts by copying the AWS, Azure, or GCP CLI commands and then run t hem in your cloud environment or you can configure a custom python script to automate the remediation steps.

[NOTE]
====
IAM automatic remediation is different from Prisma Cloud automatic remediation. The IAM module does not support the option to enable automatic remediation. Instead, xref:../manage-prisma-cloud-alerts/create-an-alert-rule.adoc#idd1af59f7-792f-42bf-9d63-12d29ca7a950[Create an Alert Rule for Run-Time Checks] follow the instructions for configuring a custom p ython script on xref:#id6591319e-c53c-4df5-826f-7fc1b09f0464[Configure and Run AWS IAM Remediation Script] or xref:#idb32d1fc5-f705-438f-a798-e9d1a791d96e[Configure and Run Azure IAM Remediation Script] to manage automatic remediation for IAM alert rules using the messaging queuing service on the respective CSP.
====

* xref:#idddd91dfc-b4d5-43fe-96cf-4b3cc447451d[Manually Remediate IAM Security Alerts]—Copy and paste the CLI commands for your AWS, Azure, or GCP environments and then execute them to manually remove excess permissions.

* *Custom python scripts*—Copy, paste, and configure the custom python scripts so that you can automate the steps of executing the CLI commands to remediate excess permissions in your AWS, Azure, or GCP environments.

** xref:#id2cbf5c9b-62aa-4a95-9340-eeaaf6f07bc4[Set up Automatic Remediation for AWS IAM Alerts]

** xref:#ide69e3eac-d058-4804-8d58-8e648893a030[Set up Automatic Remediation for Azure IAM Alerts]

** xref:#id54a76b5a-cc02-4394-b2d8-c0a64b17bc3e[Set up Remediation for GCP IAM Alerts]
+
[NOTE]
====
Automatic remediation for GCP IAM alerts is not supported.
====

+++<draft-comment>The “Deny Policies” feature is a public Beta version in GCP, as a result, the “automatic remediation” feature, which relies on the “Deny Policies” feature stays as a Beta version in the GCP GA release as well.</draft-comment>+++


[.task]
[#idddd91dfc-b4d5-43fe-96cf-4b3cc447451d]
=== Manually Remediate IAM Security Alerts

The following steps shows how you can manually remediate alerts in AWS. You can follow similar steps in Azure and GCP.

[.procedure]
. View the existing alerts.
+
To view all of the policies that triggered an alert select menu:Alerts[Overview.]

. Click *Add Filter* (image:add-filter-icon.PNG[scale=60]) and select menu:Policy{sp}Type[IAM].
+
image::iam-security-policy-type.png[scale=30]

. Select the violating policy that you want to remediate.
+
On Prisma Cloud, policies that you can remediate are indicated by the image:remediable-icon.png[scale=50] icon.
+
image::iam-security-policy-alert.png[scale=30]

. Investigate the policy violations.
+
In this example we see all the violating resources for this Okta user. Prisma Cloud provides us hints on why the alert was generated, which in this case was a result of an Okta user being able to create another IAM user—this could lead to a potential back door because even if the original Okta user is deleted, they can still log in through the second user. Prisma Cloud also provides recommended steps on how to resolve the policy violation.
+
image::iam-security-alert-violating-policy.png[scale=30]
+
After a policy violation is triggered, it is sent to the SQS queue.
+
image::send-and-receive-messages-1-alert.png[scale=25]
+
In this example the SQS queue shows 1 message which is the alert that was triggered.

. Get the remediation steps.
+
Under the *OPTIONS* column, click *Remediate*.
+
image::iam-security-remediate-button.png[scale=50]

.. Copy the CLI commands.
+
After you click *Remediate* the CLI commands appears in a popup window.
+
image::iam-security-cli-commands.png[scale=30]

.. Run the CLI commands on your AWS account. In case of your GCP account, before you run the CLI command see xref:#id54a76b5a-cc02-4394-b2d8-c0a64b17bc3e[Set up Remediation for GCP IAM Alerts].
+
After you executed the CLI commands you will have completed the remediation process and the excess privileges will be revoked. The SQS queue will now show 0 messages.
+
image::send-and-receive-messages-2-remediation.png[scale=30]


[#id2cbf5c9b-62aa-4a95-9340-eeaaf6f07bc4]
=== Set up Automatic Remediation for AWS IAM Alerts

Automate the remediation steps for your AWS IAM alerts with the help of a custom python script which receives an alert via the AWS SQS queue, extracts the alert ID and uses it to call the IAM remediation API, and runs the commands which are provided by the API response.

* xref:#id2cecf98a-db8f-4a61-9eaf-12171397bd4f[Review Prerequisites for AWS Remediation Script]
* xref:#id6591319e-c53c-4df5-826f-7fc1b09f0464[Configure and Run AWS IAM Remediation Script]


[#id2cecf98a-db8f-4a61-9eaf-12171397bd4f]
==== Review Prerequisites for AWS Remediation Script

Complete the following prerequisites so that you can set up everything you need to successfully run the python script. This includes the Prisma Cloud integrations, APIs, and python libraries.

* Integrate Prisma Cloud with Amazon SQS—This is an AWS service that allows you to send, store, and receive messages between AWS and Prisma Cloud. Follow the steps to https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/manage-prisma-cloud-alerts/send-prisma-cloud-alert-notifications-to-third-party-tools.html#idcda01586-a091-497d-87b5-03f514c70b08_id84f16f30-a2d0-44b7-85b2-4beaaef2f5bc[integrate Prisma Cloud with SQS].

* Create https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/manage-prisma-cloud-alerts/create-an-alert-rule[alert rules] and set up https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/manage-prisma-cloud-alerts/send-prisma-cloud-alert-notifications-to-third-party-tools.html[alert notifications]to Amazon SQS. All alerts triggered for the IAM policy you selected will be sent to the SQS queue.


[.task]
[#id6591319e-c53c-4df5-826f-7fc1b09f0464]
==== Configure and Run AWS IAM Remediation Script

To automatically remediate alerts, install third party libraries to create HTTP requests to your API endpoints, and edit the custom python script to include the values for the environment variables.

[.procedure]
. Copy/paste the script into a text editor or integrated development environment (IDE).
+
[userinput]
----
import json
import os
import subprocess
import boto3
import requests
import string


def log_debug(s):
    if os.environ['DEBUG']:
        print(s)


def log(s):
    print(s)


def login(user, password):
    log_debug(f'sending authentication request')
    try:
        r = requests.post(
            verify=False,
            url=f'{os.environ["API_ENDPOINT"]}/login',
            data=json.dumps({
                "username": user,
                "password": password
            }),
            headers={
                'Content-Type': 'application/json'
            }
        )
    except requests.exceptions.RequestException as e:
        log(f'Authentication request failed, error is: {e.strerror}')
        return ""
    if r.status_code != 200:
        log(f'Authentication request failed, response code is: {r.status_code}')
        return ""
    log_debug(f'Authentication request finished successfully')
    return r.json()['token']


def call_remediation_api(auth_key, alert_id):
    log_debug(f'getting remediation steps for the alert: {alert_id}')
    r = requests.post(
        verify=False,
        url=f'{os.environ["API_ENDPOINT"]}/api/v1/permission/alert/remediation',
        data=json.dumps({
            "alerts": [
                alert_id
            ]
        }),
        headers={
            'x-redlock-auth': auth_key,
            'Content-Type': 'application/json'
        }
    )
    log_debug(f'finished getting remediation steps for alert: {alert_id}')
    return r


def lambda_handler(event, context):
    account_id = os.environ['YOUR_ACCOUNT_NUMBER']
    user = os.environ['USER'] if 'USER' in os.environ else ""
    password = os.environ['PASSWORD'] if 'PASSWORD' in os.environ else ""
    auth_key = os.environ['AUTH_KEY'] if 'AUTH_KEY' in os.environ else ""
    if auth_key == "":
        auth_key = login(user, password)

    if auth_key == "":
        log(f' unable to acquire auth credentials, exiting...')
        return {
            'statusCode': 401,
        }

    sqs = boto3.resource('sqs')
    queue = sqs.get_queue_by_name(QueueName=os.environ['SQS_QUEUE_NAME'])

    # Read all queue messages
    all_messages = []
    message_batch = queue.receive_messages(MaxNumberOfMessages=10)
    while len(message_batch) > 0:
        all_messages.extend(message_batch)
        message_batch = queue.receive_messages(MaxNumberOfMessages=10)
    log_debug(f'received {len(all_messages)} messages')

    for message in all_messages:
        try:
            alert_info = json.loads(message.body)
        except json.JSONDecodeError as e:
            log(f'Can\'t parse queue message: {e.msg}, message will be deleted')
            message.delete()
            continue
        alert_id = alert_info['alertId']
        if 'account' in alert_info and 'id' in alert_info['account']:
            alert_account_id = alert_info['account']['id']
            if alert_account_id != account_id:
                log_debug(f'Alert: {alert_id} is not relevant to the current account, message will be deleted')
                message.delete()
                continue
        if 'metadata' not in alert_info:
            log_debug(f'Remediation is not supported for the alert: {alert_id}, message will be deleted')
            message.delete()
            continue
        if 'remediable' in alert_info['metadata'] and alert_info['metadata']['remediable'] is False:
            log_debug(f'Remediation is not supported for the alert: {alert_id}, message will be deleted')
            message.delete()
            continue
        try:
            log_debug(f'getting remediation steps for the alert: {alert_id}')
            r = call_remediation_api(auth_key, alert_id)
        except requests.exceptions.RequestException as e:
            log(f'Can\'t make request to the remediation api: {e.strerror}')
            continue

        if r.status_code == 401:
            auth_key = login(user, password)
            if auth_key == "":
                log(f' unable to acquire auth credentials, exiting...')
                return {
                    'statusCode': 401,
                }
            try:
                r = call_remediation_api(auth_key, alert_id)
            except requests.exceptions.RequestException as e:
                log(f'Can\'t make request to the remediation api: {e.strerror}')
                continue
        if r.status_code != 200:
            log(f'Error from the remediation API for the alert id: {alert_id}, response is: {r}, '
                f'message will be deleted')
            message.delete()
            continue

        if alert_id not in r.json()['alertIdVsCliScript']:
            log(f'Alert id not found in message, message will be deleted')
            message.delete()
            continue

        cli_commands = r.json()['alertIdVsCliScript'][alert_id]
        commands = cli_commands.replace("aws ", "/opt/aws ")
        log_debug(f' Remediation CLI commands: {commands}')
        try:
            log_debug(f'running remediation CLI commands')
            aws_cli = subprocess.Popen(
                commands,
                env=dict(os.environ),
                shell=True
            )
        except OSError as e:
            log(f'Can\'t run remediation cli commands: {e.strerror}, message will be deleted')
            message.delete()
            continue
        aws_cli.communicate()
        if aws_cli.returncode != 0:
            log(f'Can\'t run remediation cli commands: {commands}, CLI return code is {aws_cli.returncode},'
                f' message will be deleted')
            message.delete()
            continue
        log(f'Alert {alert_id} was remediated, deleting message')
        message.delete()
    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }

----

. Run the Python script in you local environment.
+
To run the python script locally you will need five python libraries. The libraries json, os, subprocess are part of the python core, that you can import after installing python. Two additional 3rd party libraries listed below are also required. Use python's default package downloader called varname:[pip], to install 3rd party libraries and frameworks via the command line.

.. Install varname:[boto3].
+
From the command line (Windows) or terminal (Linux/MacOS) type the following command:
+
pip install boto3
+
[NOTE]
====
This is the AWS SDK for python that allows you to create, configure, and manage AWS services such as SQS.
====

.. Install varname:[requests].
+
From the command line (Windows) or terminal (Linux/MacOS) type the following command:
+
pip install requests
+
[NOTE]
====
requests is a 3rd party library for making simple HTTP requests.
====

. Run the python script on AWS Lambda.
+
To run the python script on AWS Lambda you will need to download a .zip Lambda layer file and run it as a layer on your Lambda as described below:

.. Download the zipped Lambda layer file here.

.. Install it as a https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html#configuration-layers-upload[layer] for your Lambda.

... Navigate to your Lambda console and select the *Create layer* tab. Provide the details for your layer and select the option to *Upload a .zip file* and complete the upload.

... Navigate to *Code > Add Layer* and select the option for *Custom Layers*.

.. Follow the steps below to upload the remediataion script:

... Create a python project, which includes the .zip file you downloaded previously. 

... Run the following command to install requests package: 
+
screen:[pip install --target ./package requests]
+
... Run the following commands to generate a zip with the code and required packages:
+
[user input]
----
cd package
zip -r ../deployment-package.zip .
cd ..
zip -g deployment-package.zip AWSRemediationScript.py
----
+
Verify that the AWS Remediation python script and deployment-package.zip file is now in a folder called package. You can customize this process as required to suit the needs of your environment.

... In your Lambda, under the *Code* tab, choose *Upload from* and upload the deployment-package.zip. Edit *Runtime settings* and set the handler to match the script function. If using the original script it should be set to AWSRemediationScript.lambda_handler. To configure your Lambda choose *General configuration* and set the timeout to 15 minutes. Choose the role that will be used by the Lambda. 
+
[NOTE]
====
If the Lambda cannot finish all its work within 15 minutes it will timeout and will need to be executed again.  
====

. To complete Lambda configuration, update the environment variables as shown in the table below:

+
[cols="50%a,50%a"]
|===
|Environment Variable
|Value


|YOUR_ACCOUNT_NUMBER
|The account you wish to remediate. 


|SQS_QUEUE_NAME
|Name of the SQS queue to which you would like to forward alert messages. 


|API_ENDPOINT
|Your Prisma Cloud API subdomain. For example, if your tenant is https://api.prismacloud.io , then the API_ENDPOINT will be api.


|AUTH_KEY
|Your JWT authentication token string (x-redlock-auth). See the https://prisma.pan.dev/api/cloud[api reference] for more details.


|USER
|A user with the permissions to accquire and auth token.

|PASSWORD
|The User's corresponding password. 

|DEBUG
|Set to *True* by default. This will expose more logs. 

|===

. View the results.
+
After executing the python script, details related to the remediation will display in the output.
+
[userinput]
----
processing alert: {'alertStatus': 'open', 'reason': 'SCHEDULED', 'metadata': {'remediable': True}, 'alertRuleName': 'auto-remediation-test', 'resource': {'resourceId': 'ABCDEFGHIJKLMN', 'resourceTs': '1234567890', 'resourceName': 'test-resource'}, 
'firstSeen': '1605104944614', 'lastSeen': '1617799423260', 'service': 'Prisma Cloud', 'alertTs': '1234567890123', 'alertId': 'I-1234567', 'region': 'global', 'account': 
{'cloudType': 'aws', 'name': 'test-account', 'id': '1234567890'}, 'policy': {'severity': 'medium', 'policyType': 'iam', 'name': 'AWS entities with risky permissions', 'policyTs': '123456789012', 'description': 
"This policy identifies AWS IAM permissions that are risky. Ensure that the AWS entities provisioned in your AWS account don't have a risky set of permissions to minimize security risks.", 'recommendation': "Remediation for a user:

\n1. Log in to the AWS console
\n2. Ntest-resourcegate to the IAM service
\n3. Click on Users
\n4. Choose the relevant user
\n5. Under 'Permissions policies', find the relevant policy according to the alert details and remove the risky actions
\n----------------------------------------\n
Remediation for a Compute instance/Okta user that assumes a role:
\n1. Log in to the AWS console
\n2. Ntest-resourcegate to the compute service (For example, AWS EC2, AWS Lambda or AWS ECS) or login to the Okta console
\n3. Find the role used by the compute instance/Okta user
\n4. Ntest-resourcegate to the IAM service
\n5. Click on Roles
\n6. Choose the relevant role
\n7. Under 'Permissions policies', find the relevant policy according to the alert details and remove the risky actions
\n----------------------------------------\n
Remediation for a Resource-based Policy:
\n1. Log in to the AWS console
\n2. Ntest-resourcegate to the relevant service (For example, AWS S3)
\n3. Find resource-based policy of the resource
\n4. Remove the risky actions according to the alert details", 'id': 'abcdefg9-1abc-47fc-c876-j123f4567', 'labels': '[]'}, 'alertRuleId': '1234abc-abc0-1234-ab1c-abc1234567'}

alert id: I-1234567, account id: 1234567890 getting remediation steps for the alert

cli commands: aws iam create-policy --policy-name 'test-resource-prisma-restrictions-I-1234567-1' --policy-document '{"Version":"2012-10-17","Statement":[{"Resource":["arn:aws:iam::1234567890123:user/test-resource"],"Action":["iam:CreateAccessKey"],"Effect":"Deny"}]}' 
and aws iam attach-user-policy --user-name 'test-resource' --policy-arn 'arn:aws:iam::123456789012:policy/test-resource-prisma-restrictions-I-1234567-1'

running the CLI commands

{
    "Policy": {
        "PolicyName": "test-resource-prisma-I-1234567-1",
        "PolicyId": "ABCDEFGHIJKLMNO",
        "Arn": "arn:aws:iam::1234567890:policy/test-resource-prisma-restrictions-I-1234567-1",
        "Path": "/",
        "DefaultVersionId": "v1",
        "AttachmentCount": 0,
        "PermissionsBoundaryUsageCount": 0,
        "IsAttachable": true,
        "CreateDate": "2021-04-08T09:03:47+00:00",
        "UpdateDate": "2021-04-08T09:03:47+00:00"
    }
}

Deleting message
----
+
The output shows that we’re processing an alert for a resource named varname:[test-resource] which should now be gone when we view *Alerts*. The CLI commands for executing the remediation steps are shown in the output; these commands are automatically executed on your behalf by the python script. A new policy will be created in AWS that removes the excess permissions of the user.


[#ide69e3eac-d058-4804-8d58-8e648893a030]
=== Set up Automatic Remediation for Azure IAM Alerts

Automate the remediation steps for your IAM Azure alerts with the help of a custom python script—the script reads in the Azure Bus queue, collects alerts, and then goes into Azure and executes the CLI remediation steps.

* xref:#id9d092285-2b15-4fb4-acba-0f6e3defdeb8[Review Prerequisites for Azure Remediation Script]
* xref:#idb32d1fc5-f705-438f-a798-e9d1a791d96e[Configure and Run Azure IAM Remediation Script]


[#id9d092285-2b15-4fb4-acba-0f6e3defdeb8]
==== Review Prerequisites for Azure Remediation Script

Complete the following prerequisites so that you can set up everything you need to successfully run the python script. This includes the Prisma Cloud integrations, APIs, and python libraries.

* Integrate Prisma Cloud with Azure Serve Bus—This is an Azure service that allows you to send, store, and receive messages between Azure and Prisma Cloud. Follow the steps to https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/configure-external-integrations-on-prisma-cloud/integrate-prisma-cloud-with-azure-service-bus-queue[Integrate Prisma Cloud with Azure Service Bus].

* Create https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/manage-prisma-cloud-alerts/create-an-alert-rule[alert rules] and set up https://docs.paloaltonetworks.com/prisma/prisma-cloud/prisma-cloud-admin/manage-prisma-cloud-alerts/send-prisma-cloud-alert-notifications-to-third-party-tools.html[alert notifications] to Azure Service Bus. All alerts triggered for the IAM policy you selected will be sent to the Service Bus queue.


[.task]
[#idb32d1fc5-f705-438f-a798-e9d1a791d96e]
==== Configure and Run Azure IAM Remediation Script

Complete the following prerequisites so that you can set up everything you need to successfully run the python script. This includes the Prisma Cloud integrations, APIs, and python libraries.

[.procedure]
. Copy/paste the script into a text editor or integrated development environment (IDE).
+
[userinput]
----
import subprocess
import logging
import json
import requests
import os
from azure.servicebus import ServiceBusService, Message, Topic, Rule, DEFAULT_RULE_NAME

logging.basicConfig(level=os.environ.get("LOGLEVEL", "INFO"))

account_number_to_profile = {
}


def execute_command(command):
    """
    Execute the CLI command
    :param command:
    :return: Returns output on success and False on Failure
    """
    logging.info("Executing CLI command :- " + str(command))
    try:
        output = subprocess.check_output(command, shell=True, stderr=subprocess.STDOUT)
        logging.info("Command execution passed with following output : {}".format(output))
        return output
    except subprocess.CalledProcessError as e:
        logging.error("Command [{}] have failed with return code : {}".format(command, e.returncode))
        logging.error("Error Output : {}".format(e.output))
        return False


def run_azure_cli_commands(cli_commands, account_id):
    logging.info(f'Start run_azure_cli_commands cli commands: {cli_commands}')
    try:
        azure_cli = subprocess.Popen(
            "az cli_commands",
            env=dict(os.environ, AWS_PROFILE=account_number_to_profile.get(account_id)),
            shell=True
        )
    except OSError as e:
        logging.error(f'Can\'t run cli commands: {e.strerror}')
        return
    azure_cli.communicate()
    if azure_cli.returncode != 0:
        logging.error(f'return code:{azure_cli.returncode}, Can\'t run cli commands,: {cli_commands}')
        return
    logging.info(f'Finished run_azure_cli_commands cli commands: {cli_commands}')


def login_azure():
    logging.info("Start login_azure")
    execute_command("az login")
    logging.info("Finished login_azure")


def logout_azure():
    logging.info("Start logout_azure")
    execute_command("az logout")
    logging.info("Finished logout_azure")


def get_messages_from_queue():
    logging.info("Start get_messages_from_queue")
    queue_name = os.environ['SB_QUEUE_NAME']
    logging.info(f'Using Azure alerts queue: {queue_name}')
    sb_key = os.environ['SB_QUEUE_KEY']
    sb_key_name = os.environ['SB_QUEUE_KEY_NAME']
    service_bus_name_space = os.environ['SB_QUEUE_NAME_SPACE']
    bus_service = ServiceBusService(service_bus_name_space, shared_access_key_name=sb_key_name,
                                    shared_access_key_value=sb_key)

    queue = bus_service.get_queue(queue_name)
    logging.info(f'queue.message_count: {queue.message_count}')

    max_number_of_messages = 10
    all_messages = []
    messages_batch_index = 0
    while messages_batch_index
----

. Install the 3rd party libraries.
+
This script uses a total of five python libraries. Three of the libraries: varname:[subprocess], varname:[logging], and varname:[json] are part of the python core which allows you to import them into your programs after you install python. The other two libraries are varname:[requests] and varname:[azure.servicebus] which are 3rd party libraries—or—libraries that you have to install before running the script. Python has a default package downloader called varname:[pip], which can install 3rd party libraries and frameworks through the command line.

.. Install requests.
+
From the command line (Windows) or terminal (Linux/MacOS) type the following command:
+
userinput:[pip install requests] 
+
[NOTE]
====
requests is a 3rd party library for making simple HTTP requests
====

.. Install azure.servicebus.
+
From the command line (Windows) or terminal (Linux/MacOS) type the following command:
+
userinput:[pip install azure.servicebus] 
+
[NOTE]
====
varname:[azure.servicebus] is a client library for python to communicate between applications and services and implement asynchronous messaging patterns.
====

. Edit the environment variables.
+
These are mandatory variables to specify in the python script to run the commands provided by the API response and to customize the settings.
+
tt:[Optional (mac/linux only)]—Use the export command to set your environment variables.
+
If you’re not familiar with python and don’t want to edit the script then you can use the varname:[export] command to set the environment variables. Here’s the syntax for doing so:
+
* screen:[% export SB_QUEUE_KEY=your_sb_queue_key]
* screen:[% export SB_QUEUE_KEY_NAME=your_sb_queue_key_name]
* screen:[% export SB_QUEUE_NAME_SPACE=your_sb_queue_name_space]
* screen:[% export API_ENDPOINT=api_tenant]
* screen:[% export AUTH_KEY=your_jwt_token]
+
The following instructions can be executed on any operating system that has python installed. For example, Windows, macOS, and Linux.+
+
[cols="50%a,50%a"]
|===
|ENVIRONMENT VARIABLE
|VALUE


|varname:[SB_QUEUE_KEY]
|A string that represents the Service Bus queue key value.
+

+++<draft-comment>is this the Azure queue key value?</draft-comment>+++


|varname:[SB_QUEUE_KEY_NAME]
|A string that represents your Service Bus key name.


|varname:[SB_QUEUE_NAME_SPACE]
|A string that represents your Service Bus namespace.


|varname:[API_ENDPOINT]
|Your Prisma Cloud API subdomain. For example, if your tenant is `\https://api.prismacloud.io` , then the varname:[API_ENDPOINT] will be api.


|varname:[AUTH_KEY]
|Your JWT authentication token string (x-redlock-auth). See the https://prisma.pan.dev/api/cloud[api reference] for more details.

|===

. View the remediation results.
+
After you configured the python script with your environment variables, run the script to view the remediation results.

.. Run the script.
+
Open up command prompt (Windows) or terminal (Linux/MacOS) and type in the following command:
+
python script.py
+
[NOTE]
====
Replace script.py with the name of your actual script.
====

.. View the results.
+
After executing the python script, details related to the remediation will display in output.


[.task]
[#id54a76b5a-cc02-4394-b2d8-c0a64b17bc3e]
=== Set up Remediation for GCP IAM Alerts

Prisma Cloud leverages the https://cloud.google.com/iam/docs/deny-overview[Deny Policies] feature on GCP to remediate risky permissions to ensure a safe rollout in case you decide to revert the remediated risky permissions. Make sure you have done all the necessary https://cloud.google.com/iam/docs/deny-access#before-you-begin[configurations] in your GCP environment to use *Deny Policies*.

[NOTE]
====
* GCP *Deny Policies* feature does not yet support all https://cloud.google.com/iam/docs/deny-permissions-support[permissions] due to which some of the alerts can be partially remediable or not remediable. The list of permissions in Prisma Cloud IAM security will be updated as per their availability in GCP.

* *Deny Policies* is a public Beta release on GCP, so *remediation* will also be a Beta release on Prisma Cloud.
====

[.procedure]
. *Add Filter* (image:add-filter-icon.PNG[scale=60]) and select menu:Policy{sp}Type[IAM] and menu:Cloud{sp}Type[GCP].

. Select the violating policy that you want to remediate.

. Investigate the policy violations.

. Get the remediation steps.
+
Under the *OPTIONS* column, click *Remediate*.
+
.. Copy the CLI commands.
+
After you click *Remediate* the CLI commands appears in a popup window.
+
image::iam-security-gcp-remediate1.png[scale=50]

.. Run the CLI commands on your GCP account. Before you run the CLI command, see https://cloud.google.com/iam/docs/deny-overview[Deny Policies].
+
After you execute the CLI commands, the remediation process is complete and the excess privileges will be revoked.
